{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7eba2fee",
   "metadata": {},
   "source": [
    "Lecture: AI I - Basics \n",
    "\n",
    "Previous:\n",
    "[**Chapter 3.6: Additional Libraries and Tools**](../03_data/06_additionals.ipynb)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c232848e",
   "metadata": {},
   "source": [
    "# Chapter 4.1: Data Preparation with scikit-learn\n",
    "\n",
    "- [Imputation](#imputation)\n",
    "- [Scaling](#scaling)\n",
    "- [Dimensionality Reduction](#dimensionality-reduction)\n",
    "- [Pipelines](#pipelines)\n",
    "- [Feature Union](#feature-union)\n",
    "- [Column Transformations](#column-transformations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b77899d",
   "metadata": {},
   "source": [
    "__Scikit-learn__ (also known as __sklearn__) is an open-source software library for machine learning in Python. It is very popular and actively maintained. The library offers various classification, regression, and clustering algorithms. In addition, sklearn also includes algorithms for model selection, dimensionality reduction, and data preprocessing.  \n",
    "\n",
    "In this notebook, we (again) focus on data preprocessing (Data Preparation) and cover the following topics:\n",
    "- Imputation  \n",
    "- Scaling  \n",
    "- Dimensionality Reduction  \n",
    "- Pipelines  \n",
    "- Feature Union  \n",
    "- Column Transformations  \n",
    "\n",
    "The documentation for scikit-learn can be found [here](https://scikit-learn.org/stable/index.html).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14e8a406",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4eb51e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccb74b5",
   "metadata": {},
   "source": [
    "## Imputation\n",
    "\n",
    "Imputation refers to the completion of missing values (NaNs). As in pandas, there are various methods in sklearn to replace missing values. More information can be found [here](https://scikit-learn.org/stable/modules/impute.html).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8af39251",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_data = np.array([[1, 2], [np.nan, 3], [7, 6]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dcba4e",
   "metadata": {},
   "source": [
    "### One-dimensional Imputation\n",
    "\n",
    "In one-dimensional imputation, the values are replaced column by column. The class [SimpleImputer](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html#sklearn.impute.SimpleImputer) provides basic strategies for this purpose. Missing values can be replaced with a given constant value or with statistical values (mean, median, or most frequent value) of each column containing the missing values. This class also allows for different encodings of missing values.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f991f980",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# define different imputer\n",
    "mean_imputer = SimpleImputer()\n",
    "zero_imputer = SimpleImputer(strategy='constant', fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8366210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [4., 3.],\n",
       "       [7., 6.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First the imputer has to be fitted to the data, so either call first fit and then transform \n",
    "# or call fit_transform to do it in one step\n",
    "mean_imputer.fit(nan_data)\n",
    "mean_imputer.transform(nan_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3b1932b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [0., 3.],\n",
       "       [7., 6.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_imputer.fit_transform(nan_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0548ad35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4., 5.],\n",
       "       [8., 2.],\n",
       "       [6., 6.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "different_nan_data = np.array([[np.nan, 5], [8, 2], [6, 6]])\n",
    "mean_imputer.transform(different_nan_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf51804",
   "metadata": {},
   "source": [
    "__Brainstorming:__  \n",
    "<details>\n",
    "<summary>Why was np.nan replaced with 4?</summary>\n",
    "Because the mean_imputer was previously \"trained\" on the other data.  \n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>When can this behavior be an advantage?</summary>\n",
    "An advantage is that the imputation strategies or exact values used during training can also be applied at test time or in live operation.  \n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c2f197f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 5.],\n",
       "       [8., 2.],\n",
       "       [6., 6.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_imputer.transform(different_nan_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ffa7f2",
   "metadata": {},
   "source": [
    "It is also possible to replace values other than `np.nan`.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de1422f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Fischers', 'Fritz', 'fischt', 'frische', 'Fische'],\n",
       "       ['Frische', 'Fische', 'fischt', 'Fischers', 'Fritz']], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fischers_fritz = [\n",
    "    ['Fischers', '', 'fischt', 'frische', 'Fische'],\n",
    "    ['Frische', 'Fische', 'fischt', 'Fischers', '']\n",
    "]\n",
    "\n",
    "string_imputer = SimpleImputer(missing_values='', strategy='constant', fill_value='Fritz')\n",
    "string_imputer.fit_transform(fischers_fritz)          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c5d2a6",
   "metadata": {},
   "source": [
    "### Multidimensional Variant\n",
    "The multidimensional variant is significantly more complex. Roughly summarized, each missing value is modeled as a function of other features, and this estimate is then used for imputation. This process is repeated several times before the final replacements are made. This behavior is implemented by the [IterativeImputer](https://scikit-learn.org/stable/modules/generated/sklearn.impute.IterativeImputer.html#sklearn.impute.IterativeImputer).  \n",
    "\n",
    "> __Note:__ This class is still experimental.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f488edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer  \n",
    "\n",
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38194c4",
   "metadata": {},
   "source": [
    "First, we create a small dummy dataset where the values of the individual columns have a clear relationship to each other.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c766f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.],\n",
       "       [nan,  4.],\n",
       "       [ 3.,  9.],\n",
       "       [ 4., nan],\n",
       "       [ 5., 25.],\n",
       "       [ 6., 36.],\n",
       "       [nan, 49.],\n",
       "       [ 8., 64.],\n",
       "       [ 9., 81.],\n",
       "       [10., nan]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.arange(1, 11, dtype=\"float\")\n",
    "y = x * x \n",
    "\n",
    "data = np.array([x, y])\n",
    "data[(0, 1)] = np.nan\n",
    "data[(0, 6)] = np.nan\n",
    "data[(1, 3)] = np.nan\n",
    "data[(1, 9)] = np.nan\n",
    "data = data.T\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2b6ea4",
   "metadata": {},
   "source": [
    "Afterwards, we can again use `fit_transform` to replace the data.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a0ff6da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  1.        ],\n",
       "       [ 2.3175117 ,  4.        ],\n",
       "       [ 3.        ,  9.        ],\n",
       "       [ 4.        , 22.35578423],\n",
       "       [ 5.        , 25.        ],\n",
       "       [ 6.        , 36.        ],\n",
       "       [ 6.58808359, 49.        ],\n",
       "       [ 8.        , 64.        ],\n",
       "       [ 9.        , 81.        ],\n",
       "       [10.        , 83.09539114]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IterativeImputer().fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4ff3aa",
   "metadata": {},
   "source": [
    "The replacements of the `SimpleImputer`, on the other hand, look as follows.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "172942e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.   ,  1.   ],\n",
       "       [ 5.75 ,  4.   ],\n",
       "       [ 3.   ,  9.   ],\n",
       "       [ 4.   , 33.625],\n",
       "       [ 5.   , 25.   ],\n",
       "       [ 6.   , 36.   ],\n",
       "       [ 5.75 , 49.   ],\n",
       "       [ 8.   , 64.   ],\n",
       "       [ 9.   , 81.   ],\n",
       "       [10.   , 33.625]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SimpleImputer().fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a8b81a",
   "metadata": {},
   "source": [
    "__Brainstorming:__  \n",
    "<details>\n",
    "    <summary>What are the advantages of the multidimensional variant?</summary>\n",
    "    A major advantage is that the missing data is replaced depending on other data. This is often better, as there may be dependencies between the data. Example: height and weight of individuals.\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a05ad3c",
   "metadata": {},
   "source": [
    "In the following three lines of code, the iterative working method of the algorithm becomes visible.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd2588dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/.venv/lib/python3.12/site-packages/sklearn/impute/_iterative.py:895: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  1.        ],\n",
       "       [ 3.10315829,  4.        ],\n",
       "       [ 3.        ,  9.        ],\n",
       "       [ 4.        , 20.73213454],\n",
       "       [ 5.        , 25.        ],\n",
       "       [ 6.        , 36.        ],\n",
       "       [ 6.8956479 , 49.        ],\n",
       "       [ 8.        , 64.        ],\n",
       "       [ 9.        , 81.        ],\n",
       "       [10.        , 82.62527756]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IterativeImputer(max_iter=1).fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "283769ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/.venv/lib/python3.12/site-packages/sklearn/impute/_iterative.py:895: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  1.        ],\n",
       "       [ 2.34645245,  4.        ],\n",
       "       [ 3.        ,  9.        ],\n",
       "       [ 4.        , 22.28201783],\n",
       "       [ 5.        , 25.        ],\n",
       "       [ 6.        , 36.        ],\n",
       "       [ 6.61040064, 49.        ],\n",
       "       [ 8.        , 64.        ],\n",
       "       [ 9.        , 81.        ],\n",
       "       [10.        , 83.06934333]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IterativeImputer(max_iter=2).fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd114ab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  1.        ],\n",
       "       [ 2.3175117 ,  4.        ],\n",
       "       [ 3.        ,  9.        ],\n",
       "       [ 4.        , 22.35578423],\n",
       "       [ 5.        , 25.        ],\n",
       "       [ 6.        , 36.        ],\n",
       "       [ 6.58808359, 49.        ],\n",
       "       [ 8.        , 64.        ],\n",
       "       [ 9.        , 81.        ],\n",
       "       [10.        , 83.09539114]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IterativeImputer(max_iter=3).fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c57ef66",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Lecture: AI I - Basics \n",
    "\n",
    "Exercise: [**Exercise 4.1: Data Preparation**](../04_ml/exercises/01_data_preparation.ipynb)\n",
    "\n",
    "Next: [**Chapter 4.2: Machine Learning with scikit-learn**](../04_ml/02_machine_learning.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-lecture",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
