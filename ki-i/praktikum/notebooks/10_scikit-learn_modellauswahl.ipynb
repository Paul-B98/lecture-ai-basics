{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "consistent-building",
   "metadata": {},
   "source": [
    "Wahlpflichtfach Künstliche Intelligenz I: Praktikum \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gothic-ceiling",
   "metadata": {},
   "source": [
    "# 10 - Scikit-learn - Modellauswahl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daily-flour",
   "metadata": {},
   "source": [
    "Unter Modellauswahl ist die Auswahl des ML-Modells zu verstehen, dass die gegebenen Daten bestmöglich erklärt. Da es aber eine Vielzahl an unterschiedlichen Modellen gibt, die wiederum große Parameterbereiche haben, ist diese Aufgabe eine sehr kritische. Wenn zum Beispiel ein Modell ausgewählt wird, das zwar sehr gut auf den Trainingsdaten performt hat, aber auf neuen Daten kläglich versagt, hat dieses die zugrundeliegende Datenverteilung nicht gelernt. \n",
    "\n",
    "In diesem Notebook werden wir auf die folgenden Themen wingehen:\n",
    "- Kreuzvalidierung (Cross-validation)\n",
    "- Hyperparametertuning\n",
    "- Metriken und Ergebnisse\n",
    "- Visualisierung von Ergebnissen\n",
    "\n",
    "Das Thema Modelauswahl und -evaluierung wird auch sehr ausführlich im [sklearn-Benutzerhandbuch](https://scikit-learn.org/stable/model_selection.html) behandelt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "extended-drinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serial-young",
   "metadata": {},
   "source": [
    "## Kreuzvalidierung\n",
    "Das Lernen der Parameter einer Vorhersagefunktion und das Testen auf denselben Daten ist ein methodischer Fehler: Ein Modell, das einfach nur die Labels der Stichproben, die es gerade gesehen hat, wiederholen würde, hätte ein perfektes Ergebnis, würde für ungesehenen Daten aber nichts Brauchbares vorhersagen können. Diese Situation wird als Overfitting bezeichnet. Um dies zu vermeiden, ist es bei der Durchführung eines (überwachten) Experiments zum maschinellen Lernen üblich, einen Teil der verfügbaren Daten als Testset vorzuhalten.\n",
    "\n",
    "### Einfaches Aufteilen der Daten\n",
    "Um die Daten einfach nur Aufzuteilen, kann die [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)-Methode verwended werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innovative-brisbane",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# load data\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "# split the data into 2 sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "black-portfolio",
   "metadata": {},
   "source": [
    "Nun kann die Support-Vektor-Maschine mit den Trainingsdaten trainiert werden und mit den Testdaten evaluiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-mapping",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(kernel='linear', C=0.001).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heavy-newsletter",
   "metadata": {},
   "source": [
    "Ausprobieren von anderen Werten für C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-hartford",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='linear', C=0.01).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indirect-shepherd",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='linear', C=0.1).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arranged-blame",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressive-exploration",
   "metadata": {},
   "source": [
    "### Warum Kreuzvalidierung?\n",
    "Bei der Auswertung verschiedener Einstellungen (\"Hyperparameter\") für Vorhersagefunktionen, wie z. B. des C-Werts, die für eine SVM manuell gesetzt werden muss, besteht immer noch die Gefahr des Overfittings auf dem Testset, da die Parameter so lange verändert werden können, bis die Vorhersagefunktionen optimal arbeitet. Auf diese Weise kann das Wissen über das Testset in das Modell \"durchsickern\" und die Auswertungsmetriken berichten nicht mehr über die Generalisierungsleistung. Um dieses Problem zu lösen, kann ein weiterer Teil des Datensatzes als sogenanntes \"Validierungsset\" vorgehalten werden: Das Training erfolgt auf dem Trainingsset, danach wird die Auswertung auf dem Validierungsset durchgeführt, und wenn das Experiment erfolgreich zu sein scheint, kann die abschließende Auswertung auf dem Testset erfolgen.\n",
    "\n",
    "Durch die Aufteilung der verfügbaren Daten in drei Sätze wird jedoch die Anzahl der Datenpunkte, die für das Lernen des Modells verwendet werden können, drastisch reduziert. Außerdem können die Ergebnisse von einer bestimmten zufälligen Wahl für das Paar von (Trainings-, Validierungs-)Sets abhängen.\n",
    "\n",
    "Um diese Probleme zu überkommen kann das Kreuzvalidierungsverfahren angewandt werden. Bei diesem Verfahren wird immer noch ein Testset benötigt, aber das Validierungsset ist nicht länger nötig. In der Basisversion wird das Trainingsset während des Trainings in $k$ Sets unterteilt. Anschließend wird der Algorithmus $k$ mal auf $k-1$ Sets trainiert. Die Evaluierung des Modells erfolgt dabei auf dem $k$ten Set.\n",
    "\n",
    "<img src=\"https://scikit-learn.org/stable/_images/grid_search_cross_validation.png\">\n",
    "\n",
    "### Verwendung von Kreuzvalidierung\n",
    "Der einfachste Weg Kreuzvalidierung zu verwenden ist die [cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score)-Hilfsfunktion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interior-bookmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "clf = svm.SVC(kernel='linear', C=1, random_state=42)\n",
    "\n",
    "k = 5\n",
    "scores = cross_val_score(clf, X, y, cv=k)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-sydney",
   "metadata": {},
   "source": [
    "Die Funktion gibt ein Array der Länge $k$ zurück. Jedes Element ist der Score für das jeweilige Teilset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "french-organization",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "linear-salon",
   "metadata": {},
   "source": [
    "Standardmäßig wird als Ergebniss jeder Kreuzvalidierungsiteration der Wert der `score`-Methode des Modells zurückgegeben. Um dies zu ändern, kann der `scoring` Parameter gesetzt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "going-sharing",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(clf, X, y, cv=5, scoring='f1_macro')\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desperate-border",
   "metadata": {},
   "source": [
    "Einen weiteren Weg Kreuzvalidierung durchzuführen bietet die [cross_validate](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html)-Methode. Dieser können, im Gegensatz zur `cross_val_score`-Funktion, mehrere Metriken übergeben werden. Außerdem gibt die Methode zusätzlich zu den Ergebnissen auch Informationen über Laufzeiten zurück. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certain-publication",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "scoring = ['precision_macro', 'recall_macro']\n",
    "clf = svm.SVC(kernel='linear', C=1, random_state=0)\n",
    "scores = cross_validate(clf, X, y, scoring=scoring)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "favorite-monday",
   "metadata": {},
   "source": [
    "### Kreuzvalidierungsiteratoren\n",
    "An beide Funktionen kann mit Hilfe des Parameters `cv` entweder ein Integer-Wert $k$ oder ein Kreuzvalidierungsiteratoren übergeben werden. Ersteres resultiert darin, dass der [KFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) bzw. der [StratifiedKFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html)-Iterator mit $k$ folds verwendet wird. Im Zweiten fall wird der entsprechende [Kreuzvalidierungsiterator](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation-iterators) verwendet, um das Datenset während des Trainings aufzuteilen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "talented-running",
   "metadata": {},
   "source": [
    "## Hyperparametertuning\n",
    "Hyperparameter sind all die Parameter, die ein ML-Algorithmus nicht selber lernt. Zum Beispiel ist der `C`-Parameter eines SVMs ein Hyperparameter, den wir vorhin schon einmal manuell optimiert haben. Damit nicht jeder Parameter oder besser gesagt jede Parameterkombination manuell optimiert werden muss, bietet sklearn verschiedene Algorithmen dafür an. Diese Algorithmen suchen im Hyperparameterraum die besten Parameterkombinationen für den ML-Algorithmus. \n",
    "\n",
    "### Umfassende Rastersuche (Grid Search)\n",
    "Die von [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) bereitgestellte Rastersuche generiert umfassend Kandidaten aus einem mit dem Parameter `param_grid` angegebenen Raster von Parameterwerten. Zum Beispiel gibt der folgende `param_grid`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "decent-conviction",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    " ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blocked-carroll",
   "metadata": {},
   "source": [
    "an, dass zwei Raster untersucht werden sollen: eines mit einem linearen Kernel und C-Werten in [1, 10, 100, 1000] und das zweite mit einem RBF-Kernel und dem Kreuzprodukt aus C-Werten im Bereich [1, 10, 100, 1000] und Gamma-Werten in [0,001, 0,0001]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifty-gross",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# create a SVC and optimize it with a grid search\n",
    "svc = svm.SVC()\n",
    "clf = GridSearchCV(svc, param_grid)\n",
    "clf.fit(X, y)\n",
    "\n",
    "# get the best estimator\n",
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rocky-tours",
   "metadata": {},
   "source": [
    "Anzeigen aller Ergebnisse der Kreuzvalidierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convinced-botswana",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utility-wedding",
   "metadata": {},
   "source": [
    "### Zufällige Rastersuche\n",
    "Anstatt die Parameter fest vorzuschreiben können diese auch zufällig aus entsprechenden Verteilungen gezogen werden. Dafür kann die Klasse [RandomizedSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) verwendet werden. Ein beispielhaftes Grid könnte dort wie folgt aussehen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "becoming-occasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "param_grid = {'C': scipy.stats.expon(scale=100), 'gamma': scipy.stats.expon(scale=.1),\n",
    "  'kernel': ['rbf'], 'class_weight':['balanced', None]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifth-tender",
   "metadata": {},
   "source": [
    "### Schnellere Rastersuche\n",
    "Da unter Umständen aus sehr vielen Parametern die besten gefunden werden müssen, gibt es für beide vorherige Varainten auch eine schneller Implementierung. Dabei werden zuerst alle Parameterkombinationen auf einem Bruchteil der Daten trainiert und evaluiert. Anschließend werden die 50% der Parameterkombinationen entfernt, die am schlechtesten abgeschnitten haben. Dann wird die Datenmenge ein wenig erhöht und die nächste Runde beginnt. \n",
    "\n",
    "<img src=\"https://scikit-learn.org/stable/_images/sphx_glr_plot_successive_halving_iterations_001.png\">\n",
    "\n",
    "Für eine schnelle, umfassende Suche kann die Klasse [HalvingGridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingGridSearchCV.html) verwendet werden und für eine schnelle, zufällige Suche die Klasse [HalvingRandomSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingRandomSearchCV.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "devoted-deviation",
   "metadata": {},
   "source": [
    "### Rastersuche und Pipelines\n",
    "Selbstverständlich kann auch ein Pipeline-Objekt an die Rastersuche übergeben werden. Dafür müssen die Einträge im Parametergrid dann wieder das Format `<estimator>__<parameter>` haben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-course",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "# create some data\n",
    "X, y = make_moons()\n",
    "\n",
    "# setup the pipeline\n",
    "calibrated_forest = CalibratedClassifierCV(estimator=RandomForestClassifier(n_estimators=10))\n",
    "pipe = Pipeline([('select', SelectKBest()), ('model', calibrated_forest)])\n",
    "\n",
    "# define the parameter grid\n",
    "param_grid = {\n",
    "   'select__k': [1, 2],\n",
    "   'model__estimator__max_depth': [2, 4, 6, 8]\n",
    "}\n",
    "\n",
    "# fit the best parameters for the whole pipeline\n",
    "search = GridSearchCV(pipe, param_grid, cv=5).fit(X, y)\n",
    "search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "configured-springer",
   "metadata": {},
   "source": [
    "## Metriken\n",
    "Metriken werden zur Evaluation/Validierung von ML-Modellen verwendet. Die folgende Tabelle gibt ein Überblick über die meistverwendeten Scoring-Funktionen. Um beispielsweise in der Kreuzvalidierung eine andere Funktion als die Standardfunktion des ML-Algorithmuses zu verwenden, kann zum Beispiel an das `GridSearchCV`-Objekt einen Wert aus der Spalte _Scoring_ an den Parameter `scoring`übergeben werden. Für Scores gilt generell, je höher der Wert, desto besser. Daher gibt es für Metriken, die zum Beispiel Distanzen messen, negierte Metriken (`neg_mean_squared_error`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cubic-result",
   "metadata": {},
   "source": [
    "<table class=\"docutils align-default\">\n",
    "<colgroup>\n",
    "<col style=\"width: 31%\">\n",
    "<col style=\"width: 40%\">\n",
    "<col style=\"width: 29%\">\n",
    "</colgroup>\n",
    "<thead>\n",
    "<tr class=\"row-odd\"><th class=\"head\"><p>Scoring</p></th>\n",
    "<th class=\"head\"><p>Function</p></th>\n",
    "<th class=\"head\"><p>Comment</p></th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr class=\"row-even\"><td><p><strong>Classification</strong></p></td>\n",
    "<td></td>\n",
    "<td></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p>‘accuracy’</p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score\" title=\"sklearn.metrics.accuracy_score\"><code class=\"xref py py-func docutils literal notranslate\"><span class=\"pre\">metrics.accuracy_score</span></code></a></p></td>\n",
    "<td></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p>‘balanced_accuracy’</p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.balanced_accuracy_score.html#sklearn.metrics.balanced_accuracy_score\" title=\"sklearn.metrics.balanced_accuracy_score\"><code class=\"xref py py-func docutils literal notranslate\"><span class=\"pre\">metrics.balanced_accuracy_score</span></code></a></p></td>\n",
    "<td></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p>‘top_k_accuracy’</p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.top_k_accuracy_score.html#sklearn.metrics.top_k_accuracy_score\" title=\"sklearn.metrics.top_k_accuracy_score\"><code class=\"xref py py-func docutils literal notranslate\"><span class=\"pre\">metrics.top_k_accuracy_score</span></code></a></p></td>\n",
    "<td></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p>‘average_precision’</p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html#sklearn.metrics.average_precision_score\" title=\"sklearn.metrics.average_precision_score\"><code class=\"xref py py-func docutils literal notranslate\"><span class=\"pre\">metrics.average_precision_score</span></code></a></p></td>\n",
    "<td></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p>‘neg_brier_score’</p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.brier_score_loss.html#sklearn.metrics.brier_score_loss\" title=\"sklearn.metrics.brier_score_loss\"><code class=\"xref py py-func docutils literal notranslate\"><span class=\"pre\">metrics.brier_score_loss</span></code></a></p></td>\n",
    "<td></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p>‘f1’</p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score\" title=\"sklearn.metrics.f1_score\"><code class=\"xref py py-func docutils literal notranslate\"><span class=\"pre\">metrics.f1_score</span></code></a></p></td>\n",
    "<td><p>for binary targets</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p>‘f1_micro’</p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score\" title=\"sklearn.metrics.f1_score\"><code class=\"xref py py-func docutils literal notranslate\"><span class=\"pre\">metrics.f1_score</span></code></a></p></td>\n",
    "<td><p>micro-averaged</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p>‘f1_macro’</p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score\" title=\"sklearn.metrics.f1_score\"><code class=\"xref py py-func docutils literal notranslate\"><span class=\"pre\">metrics.f1_score</span></code></a></p></td>\n",
    "<td><p>macro-averaged</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p>‘f1_weighted’</p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score\" title=\"sklearn.metrics.f1_score\"><code class=\"xref py py-func docutils literal notranslate\"><span class=\"pre\">metrics.f1_score</span></code></a></p></td>\n",
    "<td><p>weighted average</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p>‘f1_samples’</p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score\" title=\"sklearn.metrics.f1_score\"><code class=\"xref py py-func docutils literal notranslate\"><span class=\"pre\">metrics.f1_score</span></code></a></p></td>\n",
    "<td><p>by multilabel sample</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p>‘neg_log_loss’</p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.log_loss.html#sklearn.metrics.log_loss\" title=\"sklearn.metrics.log_loss\"><code class=\"xref py py-func docutils literal notranslate\"><span class=\"pre\">metrics.log_loss</span></code></a></p></td>\n",
    "<td><p>requires <code class=\"docutils literal notranslate\"><span class=\"pre\">predict_proba</span></code> support</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p>‘precision’ etc.</p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score\" title=\"sklearn.metrics.precision_score\"><code class=\"xref py py-func docutils literal notranslate\"><span class=\"pre\">metrics.precision_score</span></code></a></p></td>\n",
    "<td><p>suffixes apply as with ‘f1’</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p>‘recall’ etc.</p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score\" title=\"sklearn.metrics.recall_score\"><code class=\"xref py py-func docutils literal notranslate\"><span class=\"pre\">metrics.recall_score</span></code></a></p></td>\n",
    "<td><p>suffixes apply as with ‘f1’</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p>‘jaccard’ etc.</p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.jaccard_score.html#sklearn.metrics.jaccard_score\" title=\"sklearn.metrics.jaccard_score\"><code class=\"xref py py-func docutils literal notranslate\"><span class=\"pre\">metrics.jaccard_score</span></code></a></p></td>\n",
    "<td><p>suffixes apply as with ‘f1’</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p>‘roc_auc’</p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score\" title=\"sklearn.metrics.roc_auc_score\"><code class=\"xref py py-func docutils literal notranslate\"><span class=\"pre\">metrics.roc_auc_score</span></code></a></p></td>\n",
    "<td></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p>‘roc_auc_ovr’</p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score\" title=\"sklearn.metrics.roc_auc_score\"><code class=\"xref py py-func docutils literal notranslate\"><span class=\"pre\">metrics.roc_auc_score</span></code></a></p></td>\n",
    "<td></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p>‘roc_auc_ovo’</p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score\" title=\"sklearn.metrics.roc_auc_score\"><code class=\"xref py py-func docutils literal notranslate\"><span class=\"pre\">metrics.roc_auc_score</span></code></a></p></td>\n",
    "<td></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p>‘roc_auc_ovr_weighted’</p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score\" title=\"sklearn.metrics.roc_auc_score\"><code class=\"xref py py-func docutils literal notranslate\"><span class=\"pre\">metrics.roc_auc_score</span></code></a></p></td>\n",
    "<td></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p>‘roc_auc_ovo_weighted’</p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score\" title=\"sklearn.metrics.roc_auc_score\"><code class=\"xref py py-func docutils literal notranslate\"><span class=\"pre\">metrics.roc_auc_score</span></code></a></p></td>\n",
    "<td></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p><strong>Clustering</strong></p></td>\n",
    "<td></td>\n",
    "<td></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p>‘adjusted_mutual_info_score’</p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_mutual_info_score.html#sklearn.metrics.adjusted_mutual_info_score\" title=\"sklearn.metrics.adjusted_mutual_info_score\"><code class=\"xref py py-func docutils literal notranslate\"><span class=\"pre\">metrics.adjusted_mutual_info_score</span></code></a></p></td>\n",
    "<td></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p>‘adjusted_rand_score’</p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_rand_score.html#sklearn.metrics.adjusted_rand_score\" title=\"sklearn.metrics.adjusted_rand_score\"><code class=\"xref py py-func docutils literal notranslate\"><span class=\"pre\">metrics.adjusted_rand_score</span></code></a></p></td>\n",
    "<td></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p>‘completeness_score’</p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.completeness_score.html#sklearn.metrics.completeness_score\" title=\"sklearn.metrics.completeness_score\"><code class=\"xref py py-func docutils literal notranslate\"><span class=\"pre\">metrics.completeness_score</span></code></a></p></td>\n",
    "<td></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p>‘fowlkes_mallows_score’</p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.fowlkes_mallows_score.html#sklearn.metrics.fowlkes_mallows_score\" title=\"sklearn.metrics.fowlkes_mallows_score\"><code class=\"xref py py-func docutils literal notranslate\"><span class=\"pre\">metrics.fowlkes_mallows_score</span></code></a></p></td>\n",
    "<td></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p>‘homogeneity_score’</p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.homogeneity_score.html#sklearn.metrics.homogeneity_score\" title=\"sklearn.metrics.homogeneity_score\"><code class=\"xref py py-func docutils literal notranslate\"><span class=\"pre\">metrics.homogeneity_score</span></code></a></p></td>\n",
    "<td></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p>‘mutual_info_score’</p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mutual_info_score.html#sklearn.metrics.mutual_info_score\" title=\"sklearn.metrics.mutual_info_score\"><code class=\"xref py py-func docutils literal notranslate\"><span class=\"pre\">metrics.mutual_info_score</span></code></a></p></td>\n",
    "<td></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p>‘normalized_mutual_info_score’</p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.normalized_mutual_info_score.html#sklearn.metrics.normalized_mutual_info_score\" title=\"sklearn.metrics.normalized_mutual_info_score\"><code class=\"xref py py-func docutils literal notranslate\"><span class=\"pre\">metrics.normalized_mutual_info_score</span></code></a></p></td>\n",
    "<td></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p>‘rand_score’</p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.rand_score.html#sklearn.metrics.rand_score\" title=\"sklearn.metrics.rand_score\"><code class=\"xref py py-func docutils literal notranslate\"><span class=\"pre\">metrics.rand_score</span></code></a></p></td>\n",
    "<td></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p>‘v_measure_score’</p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.v_measure_score.html#sklearn.metrics.v_measure_score\" title=\"sklearn.metrics.v_measure_score\"><code class=\"xref py py-func docutils literal notranslate\"><span class=\"pre\">metrics.v_measure_score</span></code></a></p></td>\n",
    "<td></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p><strong>Regression</strong></p></td>\n",
    "<td></td>\n",
    "<td></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p>‘explained_variance’</p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.explained_variance_score.html#sklearn.metrics.explained_variance_score\" title=\"sklearn.metrics.explained_variance_score\"><code class=\"xref py py-func docutils literal notranslate\"><span class=\"pre\">metrics.explained_variance_score</span></code></a></p></td>\n",
    "<td></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p>‘max_error’</p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"generated/sklearn.metrics.max_error.html#sklearn.metrics.max_error\" title=\"https://scikit-learn.org/stable/modules/sklearn.metrics.max_error\"><code class=\"xref py py-func docutils literal notranslate\"><span class=\"pre\">metrics.max_error</span></code></a></p></td>\n",
    "<td></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p>‘neg_mean_absolute_error’</p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html#sklearn.metrics.mean_absolute_error\" title=\"sklearn.metrics.mean_absolute_error\"><code class=\"xref py py-func docutils literal notranslate\"><span class=\"pre\">metrics.mean_absolute_error</span></code></a></p></td>\n",
    "<td></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p>‘neg_mean_squared_error’</p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error\" title=\"sklearn.metrics.mean_squared_error\"><code class=\"xref py py-func docutils literal notranslate\"><span class=\"pre\">metrics.mean_squared_error</span></code></a></p></td>\n",
    "<td></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p>‘neg_root_mean_squared_error’</p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error\" title=\"sklearn.metrics.mean_squared_error\"><code class=\"xref py py-func docutils literal notranslate\"><span class=\"pre\">metrics.mean_squared_error</span></code></a></p></td>\n",
    "<td></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p>‘neg_mean_squared_log_error’</p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_log_error.html#sklearn.metrics.mean_squared_log_error\" title=\"sklearn.metrics.mean_squared_log_error\"><code class=\"xref py py-func docutils literal notranslate\"><span class=\"pre\">metrics.mean_squared_log_error</span></code></a></p></td>\n",
    "<td></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p>‘neg_median_absolute_error’</p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.median_absolute_error.html#sklearn.metrics.median_absolute_error\" title=\"sklearn.metrics.median_absolute_error\"><code class=\"xref py py-func docutils literal notranslate\"><span class=\"pre\">metrics.median_absolute_error</span></code></a></p></td>\n",
    "<td></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p>‘r2’</p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score\" title=\"sklearn.metrics.r2_score\"><code class=\"xref py py-func docutils literal notranslate\"><span class=\"pre\">metrics.r2_score</span></code></a></p></td>\n",
    "<td></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p>‘neg_mean_poisson_deviance’</p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_poisson_deviance.html#sklearn.metrics.mean_poisson_deviance\" title=\"sklearn.metrics.mean_poisson_deviance\"><code class=\"xref py py-func docutils literal notranslate\"><span class=\"pre\">metrics.mean_poisson_deviance</span></code></a></p></td>\n",
    "<td></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p>‘neg_mean_gamma_deviance’</p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_gamma_deviance.html#sklearn.metrics.mean_gamma_deviance\" title=\"sklearn.metrics.mean_gamma_deviance\"><code class=\"xref py py-func docutils literal notranslate\"><span class=\"pre\">metrics.mean_gamma_deviance</span></code></a></p></td>\n",
    "<td></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p>‘neg_mean_absolute_percentage_error’</p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_percentage_error.html#sklearn.metrics.mean_absolute_percentage_error\" title=\"sklearn.metrics.mean_absolute_percentage_error\"><code class=\"xref py py-func docutils literal notranslate\"><span class=\"pre\">metrics.mean_absolute_percentage_error</span></code></a></p></td>\n",
    "<td></td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nearby-playing",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "Die Accuracy gibt den Anteil der korrekt klassifizierten Datenpunkte zurück.\n",
    "\n",
    "$$ accuracy(y, \\hat{y})= \\frac{1}{n_{samples}}\\sum_{i=0}^{n_{samples}-1}1(\\hat{y}_i = y_i) $$\n",
    "\n",
    "where $1(x)$ is the indicator function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "labeled-lightweight",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = [0, 2, 1, 3]\n",
    "y_true = [0, 1, 2, 3]\n",
    "accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seventh-separate",
   "metadata": {},
   "source": [
    "Wenn wir nicht normalisieren, bekommen wir die Anzahl an korrekt klassifizierten Datenpunkten zurück."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "planned-mixer",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_true, y_pred, normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contemporary-royal",
   "metadata": {},
   "source": [
    "Wenn ein Datenpunkt zu mehreren Klassen gehört, müssen alle Klassifizierungen übereinstimmen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proud-architect",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(np.array([[0, 1], [1, 1]]), np.ones((2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radical-drilling",
   "metadata": {},
   "source": [
    "### Balanced Accuracy\n",
    "Die Balanced Accuracy berechnet einen Accuracy-Wert pro Klasse. Dadurch ist sie besser für unausgeglichene Datensets geeignet.\n",
    "\n",
    "$$ balanced\\_accuracy=\\frac{1}{2}(\\frac{TP}{TP+FN}+\\frac{TN}{TN+FP})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-crest",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "y_pred = [0, 0, 0, 0]\n",
    "y_true = [0, 0, 0, 1]\n",
    "balanced_accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equipped-ethnic",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "In sklearn steht jede Zeile für das wirkliche Label und jede Spalte für das vorhergesagte Label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-count",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = [2, 0, 2, 2, 0, 1]\n",
    "y_pred = [0, 0, 2, 2, 0, 2]\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medieval-reproduction",
   "metadata": {},
   "source": [
    "Mit Hilfe der [plot_confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html)-Funktion kann die Matrix visualisiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noble-preview",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# import and split the data\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "class_names = iris.target_names\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# define the classifier and fit it\n",
    "classifier = svm.SVC(kernel='linear', C=0.01).fit(X_train, y_train)\n",
    "\n",
    "# create the plot\n",
    "fig, ax = plt.subplots(1, figsize=(10, 8))\n",
    "_ = ConfusionMatrixDisplay.from_estimator(\n",
    "    classifier, \n",
    "    X_test, \n",
    "    y_test, \n",
    "    display_labels=iris.target_names, \n",
    "    cmap=plt.cm.Blues,\n",
    "    ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toxic-broad",
   "metadata": {},
   "source": [
    "### Klassifikationsbericht\n",
    "Mit der [classification_report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)-Funktion ist es möglich sich ein Textbericht, der die wichtigsten Klassifikationsmetriken beinhaltet, zu erzeugen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-clinton",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_true = [0, 1, 2, 2, 0]\n",
    "y_pred = [0, 0, 2, 1, 0]\n",
    "target_names = ['class 0', 'class 1', 'class 2']\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "normal-light",
   "metadata": {},
   "source": [
    "Weitere Informationen zu den Metriken finden Sie [hier](https://scikit-learn.org/stable/modules/model_evaluation.html#)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empirical-timer",
   "metadata": {},
   "source": [
    "## Visualisierung von Ergebnissen\n",
    "Zur [Visualisierung von Ergebnissen](https://scikit-learn.org/stable/modules/learning_curve.html#) bietet sklearn zwei Helfermethoden. \n",
    "\n",
    "### Validtion Curve\n",
    "\n",
    "Die [validation_curve](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.validation_curve.html)-Methode hilft dabei die Tranings- und Validierungsergebnisse unter Einfluss eines Hyperparameters zu visualisieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "global-modem",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "# load and shuffel the data\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "indices = np.arange(y.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "X, y = X[indices], y[indices]\n",
    "\n",
    "# collect data for plotting\n",
    "c_values = [0.5, 1, 2, 3, 4, 5]\n",
    "train_scores, valid_scores = validation_curve(svm.SVC(kernel='linear'), X, y, \n",
    "    param_name='C', param_range=c_values, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bronze-active",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinct-workplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "listed-edward",
   "metadata": {},
   "source": [
    "Mit diesen Daten können wir jetzt einen Graphen erstellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjacent-preview",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, calculate the means and standard deviations\n",
    "train_scores_mean = train_scores.mean(axis=1)\n",
    "train_scores_std = train_scores.std(axis=1)\n",
    "valid_scores_mean = valid_scores.mean(axis=1)\n",
    "valid_scores_std = valid_scores.std(axis=1)\n",
    "\n",
    "# create the figure\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.title(\"Validation Curve of SVM with different C values\")\n",
    "plt.xlabel(\"C\")\n",
    "plt.ylabel(\"Score\")\n",
    "# plot the training score\n",
    "plt.plot(c_values, train_scores_mean, label=\"Training score\", color=\"darkorange\")\n",
    "plt.fill_between(c_values, \n",
    "                 train_scores_mean - train_scores_std, \n",
    "                 train_scores_mean + train_scores_std, \n",
    "                 color=\"darkorange\",\n",
    "                 alpha=0.2\n",
    "                )\n",
    "# plot the validation score\n",
    "plt.plot(c_values, valid_scores_mean, label=\"Cross-validation score\", color=\"navy\")\n",
    "plt.fill_between(c_values, \n",
    "                 valid_scores_mean - valid_scores_std, \n",
    "                 valid_scores_mean + valid_scores_std, \n",
    "                 color=\"navy\",\n",
    "                 alpha=0.2\n",
    "                )\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrong-italy",
   "metadata": {},
   "source": [
    "### Learning Curve\n",
    "Mit Hilfe der [learing_curve]()-Methode können wir zeigen wie der Validierungs- und Trainingscore sich verändern, wenn unterschiedliche Trainingsdatenmengen verwendet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wanted-ozone",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "# collect the data\n",
    "train_sizes, train_scores, valid_scores = learning_curve(\n",
    "    svm.SVC(kernel='linear'), X, y, train_sizes=np.arange(24, 121, 12), cv=5)\n",
    "train_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stainless-wings",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improved-blast",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secret-intention",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, calculate the means and standard deviations\n",
    "train_scores_mean = train_scores.mean(axis=1)\n",
    "train_scores_std = train_scores.std(axis=1)\n",
    "valid_scores_mean = valid_scores.mean(axis=1)\n",
    "valid_scores_std = valid_scores.std(axis=1)\n",
    "\n",
    "# create the figure\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.title(\"Learning  Curve\")\n",
    "plt.xlabel(\"Training examples\")\n",
    "plt.ylabel(\"Score\")\n",
    "# plot the training score\n",
    "plt.plot(train_sizes, train_scores_mean, label=\"Training score\", color=\"darkorange\")\n",
    "plt.fill_between(train_sizes, \n",
    "                 train_scores_mean - train_scores_std, \n",
    "                 train_scores_mean + train_scores_std, \n",
    "                 color=\"darkorange\",\n",
    "                 alpha=0.2\n",
    "                )\n",
    "# plot the validation score\n",
    "plt.plot(train_sizes, valid_scores_mean, label=\"Cross-validation score\", color=\"navy\")\n",
    "plt.fill_between(train_sizes, \n",
    "                 valid_scores_mean - valid_scores_std, \n",
    "                 valid_scores_mean + valid_scores_std, \n",
    "                 color=\"navy\",\n",
    "                 alpha=0.2\n",
    "                )\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "american-jungle",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Wahlpflichtach Künstliche Intelligenz I: Praktikum"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "90426636d83e24cdadcd62d77212f0f01714dea61fbf228ca5d2a0125536a635"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
