{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wahlpflichtfach Künstliche Intelligenz I: Praktikum\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07 - Data Cleaning und Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning und Data Preparation sind ein riesen Thema. Manche Leute behaupten, dass Data Scientists 80 % ihrer Zeit damit verbringen, ihre Daten zu bereinigen. Die Themen, die wir hier behandeln werden, sind \n",
    "\n",
    "* Umgang mit fehlenden Werten (Missing Values)\n",
    "* Entfernen von Duplikaten\n",
    "* Strukturierung von Daten\n",
    "* Entfernen von Ausreißern (Outlier)\n",
    "* Finden der richtigen Datentypen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fehlende Werte (Missing Values)\n",
    "\n",
    "Ein Sentinelwert wird verwendet, um fehlende Werte für Zahlen darzustellen. Eine spezielle Kombination von Bits steht für \"Keine Zahl\" (NaN). Dies kann man sich als das numerische Äquivalent von \"Keine\" vorstellen. In Python ist `NaN` durch die Pakete `NumPy` und `Pandas` verfügbar. Seit Pandas Version 1.0 werden fehlende Werte durch ein spezielles Objekt dargestellt: `pd.NA`.\n",
    "\n",
    "Das mag auf den ersten Blick seltsam erscheinen, beginnt aber Sinn zu machen, wenn wir über die Semantik von `NaN` oder allgemeiner `NA` als Platzhalter für einen Wert, der __N__ot **A**vailable ist, nachdenken. Da `NA` einfach einen beliebigen Wert repräsentiert, den wir nicht kennen, wäre es falsch zu sagen, dass ein Wert, den wir nicht kennen, gleich einem anderen Wert ist, den wir nicht kennen. Daher kann `NA` nicht wirklich gleich irgendetwas sein.\n",
    "\n",
    "Um explizit auf `NA` zu testen, benötigen wir eine eigene Funktion, die von `pandas` bereitgestellt wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isna(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isna(pd.NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isna(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Umgang mit fehlenden Werten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebola = pd.read_csv('data/07/ebola_country_timeseries.csv')\n",
    "ebola.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebola['Cases_Guinea'].value_counts(dropna=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verwerfen\n",
    "\n",
    "Der einfachste Weg, mit fehlenden Daten umzugehen, ist, sie einfach zu verwerfen. Dies kann jedoch zu einem immensen Datenverlust führen, je nachdem, wie die Daten organisiert sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebola.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebola.dropna(how='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auffüllen\n",
    "\n",
    "Stattdessen können fehlende Werte aufgefüllt werden, damit der Rest der Daten brauchbar bleibt. Beachten Sie, dass dies immer Artefakte einführt.\n",
    "\n",
    "Wir können mit einem konstanten Wert auffüllen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebola.fillna(0).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oder verwenden Sie einige fortgeschrittenere Strategien zur Berechnung der Daten, z. B. die Berechnung eines Mittelwerts pro Spalte. Dies kann durch jede einfache Summenstatistik ersetzt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebola.mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebola.fillna(ebola.mean(numeric_only=True)).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Einige fortgeschrittenere Techniken, wie z. B. der Expectation Maximization (EM)-Algorithmus, existieren, sind aber nicht direkt in `pandas` implementiert. \n",
    "\n",
    "Beim Umgang mit fortlaufenden Daten kann es sinnvoll sein, fehlende Werte mit vorherigen oder nachfolgenden Werten aufzufüllen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebola.fillna(method='ffill').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebola.fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fortgeschrittenes Auffüllen\n",
    "\n",
    "Pandas bietet auch erweiterte Methoden zum Auffüllen fehlender Werte. Die Funktion [interpolate](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.interpolate.html#pandas-dataframe-interpolate) bietet verschiedene Möglichkeiten, die fehlenden Werte zu interpolieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebola['Cases_Guinea'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebola['Cases_Guinea'].interpolate(method='quadratic').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Berechnungen mit fehlenden Werten\n",
    "\n",
    "Standardmäßig ist `NumPy` sehr streng bei Berechnungen mit `NA`-Werten. Jede Operation, die `NA` beinhaltet, wird `NA` ergeben. Das ist insofern korrekt, als dass der Endwert einer Operation wie `sum` nicht bekannt sein kann, wenn auch nur ein einziger Wert unbekannt ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nansum([1, 2, np.nan, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aus praktischer Sicht ist dies jedoch nicht sehr sinnvoll. Daher verfolgt pandas den Ansatz, `NA`s gnädig zu ignorieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebola['Cases_Guinea'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dieses Verhalten kann auf Wunsch geändert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebola['Cases_Guinea'].sum(skipna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entfernen von Duplikaten\n",
    "\n",
    "Duplikate können als Teil ungeordneter Daten entstehen. Es ist wichtig, sie richtig zu identifizieren und zu beseitigen, damit sie unsere Statistiken nicht beeinflussen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({\n",
    "    'a': [1, 1, 1, 2, 2, 2],\n",
    "    'b': [10, 20, 30, 40, 50, 50],\n",
    "})\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prüfen, ob eine Zeile ein Duplikat ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.duplicated()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verwerfen Sie die doppelten Zeilen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duplikatsuche auf eine Teilmenge der Spalten einschränken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.duplicated(subset='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop_duplicates(subset='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation: Daten mit Pandas analysieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datentypen\n",
    "\n",
    "### Finden der richtigen Datentypen\n",
    "\n",
    "Daten können in verschiedenen Maßstäben ausgedrückt werden. Sie müssen sicherstellen, dass Sie das Maßniveau finden, das sowohl semantisch als auch rechnerisch sinnvoll ist.\n",
    "\n",
    "Ein kurzer Abstecher zu den Maßstäben\n",
    "1. **Nominale Ebene** <br/>\n",
    "   Zahlen stellen nur Kategorien dar und nichts weiter. <br/>\n",
    "   Z.B.: Geschlechter, Farben<br/>\n",
    "   Es können berechnet werden: absolute und relative Häufigkeiten, Modus   \n",
    "   \n",
    "1. **Ordinalebene** <br/>\n",
    "   Die Reihenfolge hat eine Bedeutung.<br/>\n",
    "   Z.B.: Schulnoten, Musik-Charts, Antworten auf einer Likert-Skala<br/>\n",
    "   Sie können zusätzlich berechnen: kumulative Häufigkeiten, Median, Quantile   \n",
    "   \n",
    "1. **Intervallniveau** <br/>\n",
    "   Gleiche Intervalle sollen die gleiche Bedeutung haben.<br/>\n",
    "   Z.B.: Temperatur in Celsius, (Intelligenz-)Tests<br/>\n",
    "   Sie können zusätzlich berechnen: Mittelwert, Standardabweichung   \n",
    "\n",
    "1. **Verhältnisebene**<br/>\n",
    "   Verhältnisse vermitteln Bedeutung und es gibt einen bestimmten 0-Punkt.<br/>\n",
    "   Z.B.: Masse, Größe, Zeit, Geschwindigkeit<br/>\n",
    "   Sie können berechnen: Variationskoeffizient $c = \\frac{s}{\\bar X}$, d.h. eine normierte Standardabweichung \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kategorische Daten\n",
    "https://pandas.pydata.org/pandas-docs/stable/categorical.html\n",
    "\n",
    "Die Verwendung eines kategorischen D-Typs hat mehrere Vorteile\n",
    "\n",
    "* es hält den Speicherverbrauch niedrig\n",
    "* es macht die Daten für numerische Modellierungsalgorithmen nutzbar\n",
    "* Es signalisiert den Bibliotheken, die auf Pandas aufbauen, wie die Daten zu behandeln sind.\n",
    "* es macht die Absicht klar, dass nur bestimmte Werte in einer Spalte erlaubt sind und wie sie sich zueinander verhalten\n",
    "\n",
    "Die folgende `Serie` könnte perfekt mit Kategorien anstelle von Strings dargestellt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(['a','b', 'b', 'a', 'c', 'c'])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The string series is {s.nbytes} bytes big.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durch Angabe des `dtype` als \"category\" werden die Daten automatisch in eine kategoriale Skala umgewandelt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(['a','b', 'b', 'a', 'c', 'c'], dtype='category')\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In der Tat wird die `Serie` schon viel kleiner. Der Effekt wird bei größeren `Serien` stärker sein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The categorical series is {s.nbytes} bytes big.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kategoriale Daten werden unter der Haube mit numerischen Codes gespeichert, die den Kategorien zugeordnet sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Verwendung von `dtype='category'` erzeugt standardmäßig ungeordnete Kategorien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.cat.ordered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Accessor `cat` erlaubt das Ändern, Umbenennen und Ordnen von Kategorien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.cat.rename_categories(['x', 'y', 'z'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eine kategoriale Reihe kann auch aus `pd.Categorical` erstellt werden. Damit können Sie die Kategorien und die Reihenfolge explizit festlegen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Categorical(['a', 'b', 'c', 'a'], categories=['b', 'c'],ordered=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das `Categorical`-Objekt kann dann an den `Series`-Konstruktor übergeben werden, um eine echte `Series` zu erhalten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_series = pd.Series(\n",
    "    pd.Categorical(['a', 'b', 'c', 'a'], categories=['b', 'c', 'a'],\n",
    "                         ordered=False)\n",
    ")\n",
    "cat_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geordnete Kategorien\n",
    "\n",
    "Was bedeutet es, geordnete Kategorien zu haben?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_series2 = pd.Series(\n",
    "    pd.Categorical(['c', 'a', 'c', 'b'], categories=['b', 'c', 'a'],\n",
    "                         ordered=False)\n",
    ")\n",
    "cat_series2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_series == cat_series2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_series > cat_series2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_series.mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_series.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diese Semantik geht verloren, wenn Sie die atomaren Werte herausziehen. Nur die `Serie` ist kategorisch, nicht die einzelnen Einträge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_series.iloc[0], type(cat_series.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_series.iloc[0] < cat_series.iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun das Gleiche für eine **geordnete** kategoriale `Serie`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_ordered_series = pd.Series(\n",
    "    pd.Categorical(['a', 'b', 'c', 'a'], categories=['b', 'c', 'a', 'd'],\n",
    "                         ordered=True)\n",
    ")\n",
    "cat_ordered_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_ordered_series2 = pd.Series(\n",
    "    pd.Categorical(['c', 'a', 'c', 'b'], categories=['b', 'c', 'a', 'd'],\n",
    "                    ordered=True)\n",
    ")\n",
    "cat_ordered_series2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_ordered_series > cat_ordered_series2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_ordered_series.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_ordered_series == cat_ordered_series2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Median funktioniert nicht bei den kategorialen Reihen, kann aber mit den Codes berechnet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_ordered_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_ordered_series.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_ordered_series.cat.codes.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn Sie vorhandene Daten in einen kategorischen Typ umwandeln und die Kategorien und die Reihenfolge angeben möchten, können Sie mit `pd.CategoricalDtype` einen eigenen kategorischen Datentyp erstellen. Es funktioniert auf die gleiche Weise wie `pd.Categorical`, nur dass Sie die Daten nicht übergeben. Der neu erstellte Datentyp kann dann in einem `astype()`-Cast verwendet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = pd.Series(['a', 'b', 'c', 'a'])\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "cat_type = CategoricalDtype(categories=['b', 'c', 'a'],\n",
    "                             ordered=True)\n",
    "cat_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series.astype(cat_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schauen wir uns nun einen Datensatz aus der realen Welt und einige Diskretisierungstechniken an. Der Titanic-Datensatz enthält Merkmale über Passagiere der tragischen Titanic-Reise. Eine übliche einführende Übung zum maschinellen Lernen ist die Vorhersage des Überlebens der Passagiere auf der Grundlage der Merkmale (siehe https://www.kaggle.com/c/titanic/data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = pd.read_csv('data/07/titanic.csv')\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir nehmen alle Spalten in die Beschreibung auf, da \"Objekt\"-Spalten anders beschrieben werden als \"numerische\" Spalten und standardmäßig von der Beschreibung ausgeschlossen sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erweitern wir den Einschiffungshafen um den vollständigen Namen, um die Dinge etwas lesbarer zu machen. Dazu verwenden wir eine einfache Zusammenführungsoperation (mehr dazu später)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embarked_map = pd.DataFrame({'Embarked': ['C', 'Q', 'S'],\n",
    "                             'EmbarkedLong': ['Cherbourg', 'Queenstown', 'Southampton']})\n",
    "embarked_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = titanic.merge(embarked_map).sort_values(by='PassengerId')\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da die Spalte \"EmbarkedLong\" nur drei unterschiedliche Werte hat, ist es sinnvoll, sie mit Kategorien darzustellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['EmbarkedLong'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['EmbarkedLong'] = titanic['EmbarkedLong'].astype('category')\n",
    "titanic['EmbarkedLong'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Beschreibung für eine kategorische Spalte ist die gleiche wie für eine `Objekt`-Spalte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['EmbarkedLong'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diskretisieren kontinuierlicher Werte (Tiling)\n",
    "Manchmal ist es sinnvoll, numerische in kategorische Daten umzuwandeln. Zum Beispiel spielt bei manchen Problemen das genaue Alter einer Person keine Rolle, sondern nur, ob die Person minderjährig ist oder nicht. Dieser Konvertierungsprozess wird Kacheln genannt.\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/basics.html#discretization-and-quantiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Age'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit `cut` können wir numerische Werte diskretisieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Age'].head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.cut(titanic['Age'], bins=3).head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardmäßig wird `cut()` die Daten in gleich große Intervalle aufteilen. Da dies nur selten sinnvoll ist, können wir die Bin-Kanten selbst festlegen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.cut(titanic['Age'], bins=[0, 17, 67, 80], include_lowest=True).head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.cut(titanic['Age'], bins=[0, 17, 67, 80]).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn Sie die Bereichsgrenzen manuell einstellen, achten Sie darauf, dass Sie den gesamten Bereich abdecken, da Werte, die nicht in ein Intervall fallen, auf NA gesetzt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.cut(titanic['Age'], \n",
    "       bins=[64, 66, 67, 80],\n",
    "       labels=['child', 'grown-up', 'senior']).head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Age_coarse'] = pd.cut(titanic['Age'], bins=[0, 17, 67, 80], labels=['child', 'grown-up', 'senior'])\n",
    "titanic['Age_coarse']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eine verwandte Funktion ist `qcut()`, die an Quantilen schneidet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.qcut(titanic['Age'], 4).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Konvertierung in numerische Daten\n",
    "\n",
    "Manchmal werden numerische Daten irgendwie verdreht. pd.to_numeric\" behandelt diese Fälle und wandelt alles automatisch in den entsprechenden Typ um."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_data = pd.read_csv('data/07/numeric_data.csv')\n",
    "numeric_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_data['C'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_data['B'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_data['A'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_numeric(numeric_data['A'], errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_numeric(numeric_data['A'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_numeric(numeric_data['B'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_numeric(numeric_data['C'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`to_numeric()` funktioniert nur bei Serien, aber zum Glück können wir `apply()` verwenden!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_data.apply(pd.to_numeric, errors='coerce').dtypes #keyword-arguments are passed to the respective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(np.nan, float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotten mit Pandas\n",
    "\n",
    "Pandas bietet einige Plotting-Funktionen an, die auf den entsprechenden Funktionen von matplotlib aufbauen und diese Funktionen intern selbst aufrufen. Um deren Verhalten zu ändern, kann man ihnen eine Achse an ein matplotlib-Objekt übergeben: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.hist.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Age'].hist(density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(titanic['Age'].dropna().values, density=True)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "titanic['Age'].hist(density=True, ax=ax)\n",
    "ax.set_xlabel('Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Age_coarse'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Age_coarse'].value_counts().plot(kind='pie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_age_series = titanic['Age_coarse'].cat.add_categories(['unknown'])\n",
    "coarse_age_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_age_series.cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_age_series = coarse_age_series.fillna('unknown')\n",
    "coarse_age_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_age_series.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_age_series.value_counts().plot(kind='pie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_age_series.value_counts().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Funktion `plot()` funktioniert auch mit DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[['Age', 'Fare']].plot(kind='scatter', x='Age', y='Fare')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mergen von DataFrames\n",
    "\n",
    "Das Merging ist ein Konzept, das häufig in relationalen Datenbanken verwendet wird. Es erlaubt, mehrere Tabellen zu einer zusammenzufassen, indem die Spalten in Bezug auf die Werte in einer speziellen Schlüsselspalte verbunden werden. Es gibt verschiedene Möglichkeiten, wie dies erreicht werden kann.\n",
    "\n",
    "Die Funktion `DataFrame.merge` bietet diese aus SQL (https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html#pandas-dataframe-merge) entlehnten Funktionalitäten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'A': [1, 2, 3, 4],\n",
    "                    'B': [0, np.pi, 2 * np.pi, 3 * np.pi],\n",
    "                    'C': ['mouse', 'cat', 'dog', 'fish']})\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({'C': ['mouse', 'horse', 'lizard', 'fish'],\n",
    "                    'D': [1.0, 1.7, 3.0, 2.1],\n",
    "                    'E': [1, np.e, np.e ** 2, np.e ** 3]})\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inner Join\n",
    "\n",
    "Der innere Join nimmt die Schnittmenge der Schlüssel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.merge(df2, how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Left Outer Join\n",
    "\n",
    "Der Left Outer Join behält alle Werte aus der linken Tabelle (derjenigen, auf der merge aufgerufen wird) und verwendet `NaN`, wenn in der rechten Tabelle die entsprechenden Zeilen fehlen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.merge(df2, how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Right Outer Join\n",
    "Der Right Outer Join funktioniert genauso wie der Left Outer Join, aber statt aller Schlüssel aus der linken Tabelle werden alle Schlüssel aus der rechten Tabelle verwendet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.merge(df2, how='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outer Join\n",
    "Die Outer Join verwendet alle Schlüssel, die sowohl in der linken als auch in der rechten Tabelle vorhanden sind. Fehlende Zeilen in einer der Tabellen werden mit `NaN` aufgefüllt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.merge(df2, how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Überlappende Spaltennamen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.rename(columns={'D': 'A'})\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn es nicht implizit klar ist, auf welcher Spalte der Join stattfinden soll, müssen wir Pandas sagen, welche Spalte es verwenden soll. Es kann den Join auch auf mehreren Spalten durchführen, aber dafür müssen die dtypes der übereinstimmenden Spalten innerhalb der beiden DataFrames gleich sein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.merge(df2, how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir können Pandas mit dem Schlüsselwort-Argument `on` explizit mitteilen, auf welcher Spalte die Verknüpfung stattfinden soll. Mit dem Parameter `suffixes` können wir steuern, wie überlappende Spaltennamen im verbundenen DataFrame geändert werden sollen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.merge(df2, how='inner', on='C', suffixes=('_from_df1', '_from_df2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['A'] = df1['A'].astype(float)\n",
    "df1.merge(df2, how='inner', on=['A', 'C'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arbeiten mit Zeitreihendaten\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html  \n",
    "Der grundlegendste Baustein von Zeitreihendaten in Pandas ist der `Timestamp`. Er repräsentiert einen Moment in der Zeit mit der Genauigkeit einer Nanosekunde. Er wird ergänzt durch `Timedelta`, das eine Zeitspanne wie \"ein Monat\" repräsentiert, ohne an ein Datum gebunden zu sein, und `Period`, das eine Kombination aus beiden ist, wie \"Juni 2018\". Dabei muss `Period` eine gewisse Regelmäßigkeit haben, wie z. B. jeden Monat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timestamps (Zeitstempel)\n",
    "Timestamps können einfach aus menschenlesbaren Strings mit `pd.datetime` erstellt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime('2020-06-09')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime('9th June 20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime('06.09.2020')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für Nicht-Amerikaner und Leute, die denken, dass der Tag vor dem Monat kommen sollte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime('09.06.2020', dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime('2020-06-09 14:45')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = pd.to_datetime('2020-06-09 14:45:30.600700800')\n",
    "date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Timestamps` stellen alle Informationen über Attribute zur Verfügung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date.second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date.microsecond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date.nanosecond"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timestamps können verglichen werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date1 = pd.to_datetime('2020-06-09 14:45')\n",
    "date2 = pd.to_datetime('2020-06-09 14:46')\n",
    "date1 < date2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn eine Serie übergeben wird, gibt `to_datetime()` eine Serie (mit demselben Index) zurück, während eine Liste in einen DatetimeIndex umgewandelt wird:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(pd.Series(['Jul 31, 2009', '2010-01-10', None]), format='mixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(['2005/11/23', '2010.12.31'], format='mixed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timestamps\" können mit einem speziellen Satz von Symbolen formatiert werden. Alle diese Symbole finden Sie hier https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date.strftime('Today is a %A in %B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime('12-11-2010 00:00', format='%d-%m-%Y %H:%M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DatetimeIndex\n",
    "\n",
    "Timestamps können zur Indizierung von Daten verwendet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pd.DatetimeIndex(['2020-06-16', '2020-06-23',\n",
    "                          '2020-06-30', '2020-07-07',\n",
    "                          '2020-07-14'])\n",
    "schedule = pd.Series(['Statistical Visualization', 'SciPy and Statistical Modeling I',\n",
    "                      'Statistical Modeling II', 'Creating Experiments',\n",
    "                      'Performance Optimization'], index=index)\n",
    "schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule['2020-06-10':'2020-06-30']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So wie es NaN für Zahlen gibt, gibt es NaT (Not-A-Time) für Timestamps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pd.to_datetime(['2009/07/31', 'asd'], errors='coerce')\n",
    "dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`isnull()` prüft auf fehlende Daten in DatetimeIndex-Objekten (NaN in numerischen Arrays, None oder NaN in Objekt-Arrays, NaT in datetimelike):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesen von Zeitreihendaten\n",
    "\n",
    "Lesen Sie die Daten, die im Format \"Zeilen mit fester Breite\" formatiert sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = pd.read_fwf('data/07/ao_monthly.txt', header=None, index_col=0)\n",
    "ts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dies erzeugt einen Integer-Index anstelle des gewünschten `DateTimeIndex`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = pd.read_fwf('data/07/ao_monthly.txt', header=None, index_col=0,\n",
    "                 parse_dates=[[0, 1]], infer_datetime_format=True)\n",
    "ts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt, da unsere Reihe durch Zeitstempel indiziert ist, können wir mit zeitbezogener Semantik aggregieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.index.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.groupby(ts.index.year).mean().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.groupby(ts.index.year).mean().plot(marker='o');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit `pd.Grouper()` können wir komplexere Gruppierungen festlegen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.groupby(pd.Grouper(freq='5Y')).mean().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.groupby(pd.Grouper(freq='d')).mean().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling (Neuabtastung)\n",
    "\n",
    "Wenn Sie mit der Häufigkeit, mit der Ihre Daten abgetastet werden, nicht zufrieden sind, können Sie die Abtastfrequenz ändern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nineteenfifty = ts[ts.index.year == 1950]\n",
    "nineteenfifty.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nineteenfifty.plot(marker='o');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nineteenfifty.asfreq('12D', method='ffill').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nineteenfifty.asfreq('12D', method='ffill').plot(style='--o');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, sharex=True)\n",
    "\n",
    "# row 1\n",
    "nineteenfifty.asfreq('12D').plot(ax=ax[0], style='-o') # no fill\n",
    "# row 2\n",
    "nineteenfifty.asfreq('12D', method='ffill').plot(ax=ax[1], marker='o') # forward-fill\n",
    "nineteenfifty.asfreq('12D', method='bfill').plot(ax=ax[1], style='--o') # back-fill\n",
    "nineteenfifty.plot(ax=ax[1], style='o') # original\n",
    "\n",
    "ax[0].legend(['no fill'])\n",
    "ax[1].legend(['forward-fill', 'back-fill', 'original']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downsampling kann durch Angabe einer kleineren Frequenz erfolgen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nineteenfifty.asfreq('3M', method='ffill').plot(marker='o');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "nineteenfifty.asfreq('3M', method='ffill').plot(marker='o', ax=ax) # downsampled\n",
    "nineteenfifty.plot(ax=ax, style='--o') # original\n",
    "\n",
    "ax.legend(['3 Month', 'original']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resampling kann auch mit Aggregation durch `resample()` kombiniert werden. Schauen wir uns einige Aktiendaten an, um dies zu veranschaulichen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yahoo = pd.read_csv('data/07/yahoo_stock.csv', index_col=0, parse_dates=True)\n",
    "yahoo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = yahoo['Close']\n",
    "ts.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#dateoffset-objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.plot(alpha=0.5, style='-')\n",
    "ts.resample('BA').mean().plot(style=':')\n",
    "ts.asfreq('BA').plot(style='--')\n",
    "plt.legend(['input', 'resample', 'asfreq'], loc='upper left');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verschieben und Differenzieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_resampled = ts.asfreq('D', method='ffill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Verschieben von Daten in der Zeit kann auf zwei Arten erfolgen. Mit \"Shift\" werden die Daten tatsächlich verschoben. Dabei entstehen auf der einen Seite fehlende Werte und auf der anderen Seite gehen Daten verloren. Im Gegensatz dazu verschiebt `tshift` nur den Zeitindex der Daten und nicht die Daten selbst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3, sharey=True, figsize=(10, 8))\n",
    "\n",
    "ts_resampled.plot(ax=axes[0], title='Original')\n",
    "ts_resampled.shift(365).plot(ax=axes[1], title='shift(365)')\n",
    "ts_resampled.shift(365, \"d\").plot(ax=axes[2], title='tshift(365)')\n",
    "\n",
    "axes[0].axvline('2011', alpha=0.5, color='r', linewidth=3)\n",
    "axes[1].axvline('2011', alpha=0.5, color='r', linewidth=3)\n",
    "axes[2].axvline('2011', alpha=0.5, color='r', linewidth=3)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Verschiebung ist nützlich für Berechnungen, die Werte über Zeitschritte hinweg vergleichen. Ein Beispiel ist das Differenzieren, um den Trend in der Zeitreihe zu entfernen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ts_resampled - ts_resampled.shift(periods=1)).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für die Differenzierung stellt Pandas die komfortable Methode `diff` zur Verfügung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_resampled.diff(periods=1).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Window-Funktionen\n",
    "\n",
    "Window-Funktionen sind ähnlich wie `groupby`, da sie die Daten in verschiedene Gruppen basierend auf einem sich ändernden Fenster aufteilen. Die Punkte in jedem Fenster werden mithilfe einer zusammenfassenden Statistik aggregiert und dann wieder zu einer Zeitreihe kombiniert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rollendes Window\n",
    "\n",
    "Ein rollendes Window ist das Standardbeispiel für eine Window-Funktion. Es verschiebt ein Fenster mit fester Größe über die Zeitreihe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_resampled.plot()\n",
    "ts_resampled.rolling(365).mean().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn Sie `center=True` einstellen, wird der Punkt, der aggregiert und in die neue Serie eingefügt wird, aus der Mitte des Fensters und nicht von seinem Ende aus stammen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_resampled.plot()\n",
    "ts_resampled.rolling(365, center=True).mean().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expandierendes Window\n",
    "\n",
    "Ein expandierendes Window hat nur eine minimale Größe. Dann wird es mit jedem Schritt größer, wobei alle vorherigen Werte berücksichtigt werden. Dies ist sinnvoll, wenn Ihre Zeitreihe einen stationären Wert misst, der nur um einen Mittelwert schwankt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_resampled.plot()\n",
    "ts_resampled.expanding(min_periods=365).mean().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential gewichtete Window\n",
    "\n",
    "Ein exponentiell gewichtetes Window funktioniert wie ein expandierendes Fenster, gibt aber neueren Datenpunkten eine exponentiell höhere Gewichtung in allen Berechnungen. Es kann also als eine glatte Version eines rollenden Window betrachtet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_resampled.plot()\n",
    "ts_resampled.ewm(com=50.5, min_periods=5).mean().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timedeltas und Perioden\n",
    "\n",
    "Timedeltas können zu Timestamps hinzugefügt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = pd.to_timedelta('1 day')\n",
    "delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule.index += delta\n",
    "schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime('2019-08-15') - pd.to_datetime('2018-06-04')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule.index += (pd.to_datetime('2019-08-15') - pd.to_datetime('2018-06-05'))\n",
    "schedule.index = schedule.index.date\n",
    "schedule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Kombination von Timestamps und Timedeltas ermöglicht eine schöne Arithmetik mit Datumsangaben:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "friday = pd.Timestamp('2018-01-05')\n",
    "saturday = friday + pd.to_timedelta('1 day')\n",
    "saturday, saturday > friday, saturday - friday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es gibt sogar Geschäftstage in Pandas (Freitag --> Montag):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "friday = pd.Timestamp('2018-01-05')\n",
    "monday = friday + pd.offsets.BDay()\n",
    "monday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### date_range\n",
    "\n",
    "Ein bequemerer Weg, einen solchen Index zu erstellen, ist die Verwendung von `date_range`.  \n",
    "Perioden\" gibt an, wie viele Einträge wir wollen, alternativ könnten wir einen expliziten \"Stopp\" setzen. `freq` gibt an, wie die Einträge beabstandet sind. Die vollständige Liste der möglichen Offsets finden Sie hier http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases. Die Syntax ist also sehr ähnlich zu \"range(start, stop, step)\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pd.DatetimeIndex(['2020-06-16', '2020-06-23',\n",
    "                          '2020-06-30', '2020-07-07',\n",
    "                          '2020-07-14'])\n",
    "schedule = pd.Series(['Statistical Visualization', 'SciPy and Statistical Modeling I',\n",
    "                      'Statistical Modeling II', 'Creating Experiments',\n",
    "                      'Performance Optimization'], index=index)\n",
    "schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pd.date_range('2018-06-04', periods=5, freq='W')\n",
    "index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beachten Sie, dass `freq='W'` nicht eine einfache wöchentliche Häufigkeit bedeutet, sondern vielmehr **das Ende der Woche für alle diese Daten**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pd.date_range('2018-06-04', periods=5, freq='7D')\n",
    "index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas ist schlau im Ableiten von Frequenzen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DatetimeIndex(['2018-01-01', '2018-01-03', '2018-01-05'], freq='infer')\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = pd.Series(range(len(tmp)), index=tmp)\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.resample('D').sum().index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternativ könnten wir auch einen `period`-Index verwenden, um zu signalisieren, dass ein Topic zu einer ganzen Woche gehört."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prd = pd.Period('2018-06-04', '7D')\n",
    "prd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prd.freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pd.period_range('2018-06-04', periods=5, freq='W')\n",
    "schedule = pd.Series(['Statistical Visualization', 'SciPy and Statistical Modeling I',\n",
    "                      'Statistical Modeling II', 'Creating Experiments',\n",
    "                      'Performance Optimization'], index=index)\n",
    "schedule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sie können einfach zwischen `Timestamp` und Periode konvertieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule = schedule.to_timestamp()\n",
    "schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule.to_period(freq='W')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prd.to_timestamp().to_period(freq='2D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zugriff auf Werte in Serien\n",
    "\n",
    "Für Serien und Indizes, die von normalen NumPy-Arrays unterstützt werden, gibt Series.array ein neues arrays.PandasArray zurück, das eine dünne (nicht kopierbare) Hülle um ein numpy.ndarray ist. PandasArray ist für sich genommen nicht besonders nützlich, aber es bietet die gleiche Schnittstelle wie jedes Erweiterungsarray, das in Pandas oder von einer Bibliothek eines Drittanbieters definiert wurde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.period_range('2000', periods=4)\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([1, 2, 3]).array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(idx.to_numpy()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erste Info zu allem, was mit Zeitreihen zu tun hat: https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html\n",
    "\n",
    "Zusätzlich: Ein komplettes Tutorial zur Zeitreihenanalyse. Es beinhaltet den Umgang mit Zeitzonen sowie grundlegende Zeitreihenvorhersage und -klassifikation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explorative Datenanalyse\n",
    "\n",
    "Die explorative Datenanalyse (EDA) beschreibt den Prozess des Aufbaus einer Intuition für unsere Daten. Er wird durch eine Kombination von Datentransformationen und Visualisierungen erreicht. Typische Schritte im Prozess der EDA sind:\n",
    "\n",
    "\n",
    "1. Recherchieren der Felder des Datensatzes \n",
    "2. Hypothesen bilden/Untersuchungsthemen entwickeln, die untersucht werden sollen \n",
    "3. Daten zusammenstellen \n",
    "3. Qualität der Daten beurteilen \n",
    "4. Daten profilieren \n",
    "5. Untersuchen Sie jede einzelne Variable im Datensatz \n",
    "6. Beurteilen Sie die Beziehung zwischen jeder Variable und dem Ziel \n",
    "7. Beurteilen Sie Wechselwirkungen zwischen den Variablen \n",
    "8. Daten über viele Dimensionen hinweg erforschen \n",
    "\n",
    "EDA ist sehr wichtig, da wir nicht beurteilen können, ob unsere Modellierung Sinn macht, wenn wir kein Gespür für unsere Daten haben. Während jede Analyse mit EDA beginnt, werden Sie immer wieder zu ihr zurückkehren, wenn Sie neue Ergebnisse aus der Modellierung erhalten.\n",
    "\n",
    "Hier stellen wir Pivot-Tabellen als eine einfache Möglichkeit vor, die Beziehungen zwischen Variablen zu untersuchen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivot für die Analyse \n",
    "\n",
    "Letztes Mal haben wir Pivot-Tabellen als eine Möglichkeit vorgestellt, unordentliche Daten neu zu strukturieren. Ursprünglich sind sie jedoch eine Operation, um tabellarische Zusammenfassungen von Daten zu erstellen. Sie können als bequeme Abkürzung für ein zweidimensionales Groupby verwendet werden. Schauen wir uns zuerst ein normales Groupby an:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.groupby('Sex').mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nehmen wir an, wir wollen den Einfluss von Geschlecht und Passagierklasse auf die Überlebensrate im Titanic-Datensatz analysieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.groupby(['Sex', 'Pclass'])['Survived'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn Sie den Index zurücksetzen, sieht das Ganze etwas schöner aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.groupby(['Sex', 'Pclass'])['Survived'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für Leute, die an das tidy Format gewöhnt sind, ist dies intuitiv zu lesen. Vielleicht möchten Sie aber trotzdem die zweite Variable in den Spaltenüberschriften haben. Dies nennt man eine \"Pivot-Tabelle\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.groupby(['Sex', 'Pclass'])['Survived'].mean().unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um genau das zu tun, bietet pandas eine Abkürzung an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.pivot_table(values='Survived', index='Sex', columns='Pclass')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pivot-Tabellen können auch die Ränder, d. h. die über Zeilen und Spalten aggregierten Werte, enthalten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.pivot_table(values='Survived', index='Sex', columns='Pclass', margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardmäßig aggregiert `pivot_table` mit dem Mittelwert, aber wir können auch alle in `groupby` verfügbaren Funktionen auswählen oder unsere eigenen verwenden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.pivot_table(values='Fare', index='Sex', columns='Pclass', aggfunc=[min, max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Kombination von mehr als zwei Variablen ist ebenfalls möglich, indem sie entweder in den Zeilen oder in den Spalten gestapelt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.pivot_table(values='Fare', index=['Sex', 'EmbarkedLong'], columns='Pclass',aggfunc='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Age_coarse'] = pd.cut(titanic['Age'], bins=[0, 17, 67, 80], labels=['child', 'grown-up', 'senior'])\n",
    "titanic['Age_coarse']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Tool [`pivottablejs`](https://github.com/nicolaskruchten/pivottable) ermöglicht es Ihnen, Daten mit Pivotables per Drag'n'Drop schnell zu erkunden. Bei der Verwendung eines solchen grafischen Werkzeugs sollten Sie darauf achten, dass Sie die interessanten Dinge in Code umwandeln, damit sie nach dem Schließen des Notizbuchs nicht verloren gehen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pivottablejs import pivot_ui\n",
    "pivot_ui(titanic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profiling\n",
    "\n",
    "Wenn man eine explorative Datenanalyse durchführt, müssen viele Aufgaben jedes Mal neu durchgeführt werden, damit sie automatisiert werden können. Werkzeuge wie `pandas_profiling` können Summeries erstellen, die Einblicke in viele Standardfragen geben, die Sie an einen Datensatz stellen können. Allerdings kommt mit der Abstraktion auch weniger Flexibilität, so dass Werkzeuge wie dieses immer nur einen Teil Ihrer Arbeit erledigen und manchmal vielleicht gar nicht das tun, was Sie wollen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ydata_profiling import ProfileReport\n",
    "ProfileReport(titanic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im folgenden Tutorial erfahren Sie mehr über Werkzeuge und Prozesse der explorativen Datenanalyse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Wahlpflichtach Künstliche Intelligenz I: Praktikum"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
